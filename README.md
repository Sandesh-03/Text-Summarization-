# ğŸ“ Text Summarization Application

![Python](https://img.shields.io/badge/Python-Backend-yellow?logo=python&style=flat-square)
![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)

This repository contains a **Text Summarization Application** that leverages NLP techniques to summarize long pieces of text. The project includes a data ingestion pipeline and an organized logging system to track the data processing stages. ***Forked from the Krish Naik repository***

---

## ğŸ“œ Description

The **Text Summarization** application includes several stages such as **data ingestion**, **data extraction**, and **model training**. This project aims to simplify the process of summarizing large text files by providing an easy-to-use pipeline for training and testing NLP models.

Key features:
- **Data Ingestion Pipeline**: Downloads and extracts data from a given URL.
- **Text Processing**: Cleans and prepares the data for training.
- **Logging System**: Tracks each stage of the data processing and model training using logging.

---

## ğŸš€ Running Steps

### ğŸ›  Backend Setup

   1. **Clone the repository:**
      ```
      git clone https://github.com/Sandesh-03/Text-Summarization-/tree/main
      cd Text-Summarization-
      
      ```

  3. **Install the required Python dependencies:**
      ```
     pip install -r requirements.txt
      
      ```
  4. **Run The porject**
      ```
      python api.py
      
      ```
 The server will start running at http://127.0.0.1:5001.
 
---

## ğŸ“‚ Project Structure

  ```
  root
â”œâ”€â”€ src/                  # Source code
â”‚   â”œâ”€â”€ textSummarizer/   # Main module for text summarization
â”‚   â”‚   â”œâ”€â”€ __init__.py   # Initialize package
â”‚   â”‚   â”œâ”€â”€ config/       # Configuration files for the project
â”‚   â”‚   â”‚   â””â”€â”€ configuration.py # Configuration manager
â”‚   â”‚   â”œâ”€â”€ components/   # Code components for processing data
â”‚   â”‚   â”‚   â”œâ”€â”€ data_ingestion.py # Data ingestion logic
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ logging/      # Logging configuration
â”‚   â”‚   â”œâ”€â”€ pipeline/     # Data processing pipeline
â”‚   â”‚   â”‚   â”œâ”€â”€ stage_01_data_ingestion.py # Data ingestion pipeline
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ constants/    # Constants used across the app
â”‚   â”‚   â”œâ”€â”€ entity/       # Data models
â”‚   â”‚   â”œâ”€â”€ utils/        # Utility functions for reading YAML, file handling
â”‚   â”‚   â””â”€â”€ logging/__init__.py
â”‚   â”œâ”€â”€ config.yaml       # Configuration YAML file for paths
â”œâ”€â”€ app.py                # Main entry point for the application
â”œâ”€â”€ main.py               # Script to run data ingestion pipeline
â”œâ”€â”€ Dockerfile            # Docker configuration file
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ setup.py              # Setup for packaging the project
â””â”€â”€ params.yaml           # Parameter file for the application
  
  ```


---

## âœ¨ Features

- ğŸŒ Data Ingestion: Downloads and extracts data from a source URL.
- ğŸ§  Text Summarization: Future feature to implement text summarization algorithms.
- ğŸ¨ Logging: Comprehensive logging at every stage of data processing to ensure transparency.
- ğŸ”§ Pipeline: Modular pipeline for handling data ingestion, extraction, and model training.

